# ğŸ“Š Analyst-9000

> A conversational AI agent powered by **LangGraph** that processes e-commerce data and derives meaningful business insights using natural language.

---

## ğŸ“ Project Structure

```
analyst-9000/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ analyst_9000/
â”‚       â”œâ”€â”€ main.py                     # Application entry point
â”‚       â”œâ”€â”€ frontend/
â”‚       â”‚   â””â”€â”€ index.html              # Static chatbot UI
â”‚       â””â”€â”€ backend/
â”‚           â”œâ”€â”€ ai_core/
â”‚           â”‚   â”œâ”€â”€ graph/
â”‚           â”‚   â”‚   â”œâ”€â”€ graph.py        # LangGraph definition
â”‚           â”‚   â”‚   â”œâ”€â”€ nodes.py        # Graph nodes (router, QA, SQL, etc.)
â”‚           â”‚   â”‚   â”œâ”€â”€ states.py       # Agent state schema
â”‚           â”‚   â”‚   â””â”€â”€ tools.py        # BigQuery tool
â”‚           â”‚   â”œâ”€â”€ llm/
â”‚           â”‚   â”‚   â”œâ”€â”€ registry.py     # Model registry (configurable models)
â”‚           â”‚   â”‚   â”œâ”€â”€ callbacks.py    # Custom LLM callbacks for monitoring
â”‚           â”‚   â”‚   â””â”€â”€ llm_utils.py    # Reasoning budget utilities
â”‚           â”‚   â””â”€â”€ prompts/
â”‚           â”‚       â”œâ”€â”€ router.py       # Intent classification prompt
â”‚           â”‚       â”œâ”€â”€ qa_model.py     # General QA assistant prompt
â”‚           â”‚       â”œâ”€â”€ sql_generator.py # SQL generation prompt
â”‚           â”‚       â””â”€â”€ response_synthesizer.py # Data-to-insight prompt
â”‚           â”œâ”€â”€ core/
â”‚           â”‚   â”œâ”€â”€ config.py           # Application settings
â”‚           â”‚   â”œâ”€â”€ constants.py        # Configuration constants
â”‚           â”‚   â”œâ”€â”€ logger.py           # Structured JSON logging + webhook
â”‚           â”‚   â”œâ”€â”€ bigquery_handler.py # BigQuery client & schema extraction
â”‚           â”‚   â”œâ”€â”€ session_store.py    # Async session store (PostgreSQL/SQLite)
â”‚           â”‚   â””â”€â”€ setup.py            # Logging initialization
â”‚           â”œâ”€â”€ routers/
â”‚           â”‚   â”œâ”€â”€ chatbot.py          # Chat API endpoints
â”‚           â”‚   â””â”€â”€ health.py           # Health check endpoint
â”‚           â”œâ”€â”€ services/
â”‚           â”‚   â”œâ”€â”€ app_startup/        # FastAPI lifespan & configuration
â”‚           â”‚   â”œâ”€â”€ chatbot/            # Chat completion orchestration
â”‚           â”‚   â””â”€â”€ chat_history/       # Conversation persistence
â”‚           â”œâ”€â”€ schemas/
â”‚           â”‚   â”œâ”€â”€ api_schemas.py      # API request/response models
â”‚           â”‚   â”œâ”€â”€ db_schemas.py       # Database models
â”‚           â”‚   â””â”€â”€ llm_output.py       # Structured LLM outputs
â”‚           â”œâ”€â”€ helpers/
â”‚           â”‚   â”œâ”€â”€ utils.py            # Utility functions
â”‚           â”‚   â””â”€â”€ sql_queries/        # SQL templates
â”‚           â”œâ”€â”€ middleware/
â”‚           â”‚   â””â”€â”€ middleware.py       # Correlation ID middleware
â”‚           â””â”€â”€ exceptions/
â”‚               â””â”€â”€ api_exceptions.py   # Custom exception handlers
â”œâ”€â”€ secrets/
â”‚   â””â”€â”€ credentials.json                # GCP service account (you create this)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ analyst_9000.db                 # SQLite database (auto-created)
â”œâ”€â”€ docker-compose.yml                  # Docker deployment
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env                                # Environment variables (you create this)
â””â”€â”€ .env_example                        # Template for .env
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.13+**
- **Google Cloud Platform** account with BigQuery access
- **Gemini API key** from [Google AI Studio](https://aistudio.google.com)

---

### Step 0: Clone the Repository

```bash
git clone <repository-url>
cd langraph-ecommerce-agent
```

> ğŸ“ All subsequent commands should be run from the root folder of the repository.

---

### Step 1: Create Environment File

Create a `.env` file in the project root with at least your Gemini API key:

```bash
# Required
GEMINI_API_KEY=your_gemini_api_key_here
```

> ğŸ’¡ Get your API key from [Google AI Studio](https://aistudio.google.com)

---

### Step 2: Set Up BigQuery Credentials

1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create a **Service Account** with the following roles:
   - `BigQuery Job User`
   - `BigQuery Read Session User`
3. Generate a **JSON key** for the service account
4. Rename the file to `credentials.json`
5. Place it in the `secrets/` folder

```
secrets/
â””â”€â”€ credentials.json   # Your GCP service account key
```

---

### Step 3 (Optional): Configure Monitoring

Add these to your `.env` file for enhanced observability:

```bash
# Webhook for error notifications (e.g., Slack, Discord, webhook.site)
WEBHOOK_URI="https://webhook.site/your-webhook-id"

# LangSmith tracing for LLM monitoring
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=your_langsmith_api_key
LANGSMITH_PROJECT=your-project-name
```
> ğŸ’¡ Get your API key from [LangSmith](https://smith.langchain.com)
---

## ğŸ–¥ï¸ Deployment Options

### Option 1: Local Development

1. **Install [uv](https://docs.astral.sh/uv/)** (Python package manager):
   ```bash
   curl -LsSf https://astral.sh/uv/install.sh | sh
   ```

2. **Install dependencies**:
   ```bash
   uv sync
   ```

3. **Activate the virtual environment**:
   ```bash
   source .venv/bin/activate
   ```

4. **Run the application**:
   ```bash
   analy
   ```

5. **Access the chatbot**: Open [http://localhost:6757](http://localhost:6757)

> ğŸ“ Local development uses **SQLite** for session storage automatically.

---

### Option 2: Docker Deployment

1. **Build and run with Docker Compose**:
   ```bash
   docker compose up --build
   ```

2. **Access the chatbot**: Open [http://localhost:6757](http://localhost:6757)

> ğŸ“ Docker deployment uses **PostgreSQL** for session storage.

**To stop**:
```bash
docker compose down
```

**To reset data** (including PostgreSQL):
```bash
docker compose down -v
```

---

## ğŸ’¬ Using the Chatbot

Once running, you'll find a modern chatbot interface where you can:

- **Select Model**: Choose between `Flash` (fast) or `Pro` (more capable)
- **Adjust Temperature**: Control response creativity (0.0 = deterministic, 1.0 = creative)
- **Set Reasoning Effort**: `Low`, `Medium`, or `High` thinking budget

### This isn't just a query agentâ€”it's a full chatbot with memory!

You can have natural conversations, ask follow-up questions, and the agent remembers context within a session.

---

## ğŸ“Š Example Queries

Try these queries to explore your e-commerce data:

```
Show me the top 5 best-selling products (by total revenue) over the last 12 months.
```

```
What were the top 3 product categories by revenue in the last quarter?
```

```
Which products have the highest profit margins?
```

```
What is the average order value for repeat customers versus new customers?
```

```
Show me the historical sales trends for the past year.
```

```
Which product categories have the highest profit margin, and which are underperforming?
```

```
Segment customers into 3â€“4 groups based on their total lifetime spend and number of orders, 
and summarise each segment (size, % of revenue, average order value).
```

---

## ğŸ”§ Configuration

Key settings in `src/analyst_9000/backend/core/constants.py`:

| Constant | Default | Description |
|----------|---------|-------------|
| `LOCAL_DEV_PORT` | `6757` | Development server port |
| `MAX_ITERATIONS` | `3` | Max SQL retry attempts |
| `MAX_HISTORY_MESSAGES` | `30` | Messages kept in context |
| `DB_POOL_SIZE` | `5` | Connection pool size |
| `DB_MAX_OVERFLOW` | `10` | Max overflow connections |

---
