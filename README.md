# üìä Analyst-9000

> A conversational AI agent powered by **LangGraph** that processes e-commerce data and derives meaningful business insights using natural language.

---

## üìÅ Project Structure

```
analyst-9000/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ analyst_9000/
‚îÇ       ‚îú‚îÄ‚îÄ main.py                     # Application entry point
‚îÇ       ‚îú‚îÄ‚îÄ frontend/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ index.html              # Static chatbot UI
‚îÇ       ‚îî‚îÄ‚îÄ backend/
‚îÇ           ‚îú‚îÄ‚îÄ ai_core/
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ graph/
‚îÇ           ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph.py        # LangGraph definition
‚îÇ           ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nodes.py        # Graph nodes (router, QA, SQL, etc.)
‚îÇ           ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ states.py       # Agent state schema
‚îÇ           ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools.py        # BigQuery tool
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ llm/
‚îÇ           ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ registry.py     # Model registry (configurable models)
‚îÇ           ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ callbacks.py    # Custom LLM callbacks for monitoring
‚îÇ           ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_utils.py    # Reasoning budget utilities
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ prompts/
‚îÇ           ‚îÇ       ‚îú‚îÄ‚îÄ router.py       # Intent classification prompt
‚îÇ           ‚îÇ       ‚îú‚îÄ‚îÄ qa_model.py     # General QA assistant prompt
‚îÇ           ‚îÇ       ‚îú‚îÄ‚îÄ sql_generator.py # SQL generation prompt
‚îÇ           ‚îÇ       ‚îî‚îÄ‚îÄ response_synthesizer.py # Data-to-insight prompt
‚îÇ           ‚îú‚îÄ‚îÄ core/
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Application settings
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ constants.py        # Configuration constants
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ logger.py           # Structured JSON logging + webhook
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ bigquery_handler.py # BigQuery client & schema extraction
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ session_store.py    # Async session store (PostgreSQL/SQLite)
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ setup.py            # Logging initialization
‚îÇ           ‚îú‚îÄ‚îÄ routers/
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ chatbot.py          # Chat API endpoints
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ health.py           # Health check endpoint
‚îÇ           ‚îú‚îÄ‚îÄ services/
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ app_startup/        # FastAPI lifespan & configuration
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ chatbot/            # Chat completion orchestration
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ chat_history/       # Conversation persistence
‚îÇ           ‚îú‚îÄ‚îÄ schemas/
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ api_schemas.py      # API request/response models
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ db_schemas.py       # Database models
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ llm_output.py       # Structured LLM outputs
‚îÇ           ‚îú‚îÄ‚îÄ helpers/
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ utils.py            # Utility functions
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ sql_queries/        # SQL templates
‚îÇ           ‚îú‚îÄ‚îÄ middleware/
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ middleware.py       # Correlation ID middleware
‚îÇ           ‚îî‚îÄ‚îÄ exceptions/
‚îÇ               ‚îî‚îÄ‚îÄ api_exceptions.py   # Custom exception handlers
‚îú‚îÄ‚îÄ secrets/
‚îÇ   ‚îî‚îÄ‚îÄ credentials.json                # GCP service account (you create this)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ analyst_9000.db                 # SQLite database (auto-created)
‚îú‚îÄ‚îÄ docker-compose.yml                  # Docker deployment
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ .env                                # Environment variables (you create this)
‚îî‚îÄ‚îÄ .env_example                        # Template for .env
```

---

## üöÄ Getting Started

### Prerequisites

- **Python 3.13+**
- **Google Cloud Platform** account with BigQuery access
- **Gemini API key** from [Google AI Studio](https://aistudio.google.com)

---

### Step 1: Create Environment File

Create a `.env` file in the project root with at least your Gemini API key:

```bash
# Required
GEMINI_API_KEY=your_gemini_api_key_here
```

> üí° Get your API key from [Google AI Studio](https://aistudio.google.com)

---

### Step 2: Set Up BigQuery Credentials

1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create a **Service Account** with the following roles:
   - `BigQuery Job User`
   - `BigQuery Read Session User`
3. Generate a **JSON key** for the service account
4. Rename the file to `credentials.json`
5. Place it in the `secrets/` folder

```
secrets/
‚îî‚îÄ‚îÄ credentials.json   # Your GCP service account key
```

---

### Step 3 (Optional): Configure Monitoring

Add these to your `.env` file for enhanced observability:

```bash
# Webhook for error notifications (e.g., Slack, Discord, webhook.site)
WEBHOOK_URI="https://webhook.site/your-webhook-id"

# LangSmith tracing for LLM monitoring
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=your_langsmith_api_key
LANGSMITH_PROJECT=your-project-name
```

---

## üñ•Ô∏è Deployment Options

### Option 1: Local Development

1. **Install [uv](https://docs.astral.sh/uv/)** (Python package manager):
   ```bash
   curl -LsSf https://astral.sh/uv/install.sh | sh
   ```

2. **Install dependencies**:
   ```bash
   uv sync
   ```

3. **Activate the virtual environment**:
   ```bash
   source .venv/bin/activate
   ```

4. **Run the application**:
   ```bash
   analy
   ```

5. **Access the chatbot**: Open [http://localhost:6757](http://localhost:6757)

> üìù Local development uses **SQLite** for session storage automatically.

---

### Option 2: Docker Deployment

1. **Build and run with Docker Compose**:
   ```bash
   docker compose up --build
   ```

2. **Access the chatbot**: Open [http://localhost:6757](http://localhost:6757)

> üìù Docker deployment uses **PostgreSQL** for session storage.

**To stop**:
```bash
docker compose down
```

**To reset data** (including PostgreSQL):
```bash
docker compose down -v
```

---

## üí¨ Using the Chatbot

Once running, you'll find a modern chatbot interface where you can:

- **Select Model**: Choose between `Flash` (fast) or `Pro` (more capable)
- **Adjust Temperature**: Control response creativity (0.0 = deterministic, 1.0 = creative)
- **Set Reasoning Effort**: `Low`, `Medium`, or `High` thinking budget

### This isn't just a query agent‚Äîit's a full chatbot with memory!

You can have natural conversations, ask follow-up questions, and the agent remembers context within a session.

---

## üìä Example Queries

Try these queries to explore your e-commerce data:

```
Show me the top 5 best-selling products (by total revenue) over the last 12 months.
```

```
What were the top 3 product categories by revenue in the last quarter?
```

```
Which products have the highest profit margins?
```

```
What is the average order value for repeat customers versus new customers?
```

```
Show me the historical sales trends for the past year.
```

```
Which product categories have the highest profit margin, and which are underperforming?
```

```
Segment customers into 3‚Äì4 groups based on their total lifetime spend and number of orders, 
and summarise each segment (size, % of revenue, average order value).
```

---

## üîß Configuration

Key settings in `src/analyst_9000/backend/core/constants.py`:

| Constant | Default | Description |
|----------|---------|-------------|
| `LOCAL_DEV_PORT` | `6757` | Development server port |
| `MAX_ITERATIONS` | `3` | Max SQL retry attempts |
| `MAX_HISTORY_MESSAGES` | `30` | Messages kept in context |
| `DB_POOL_SIZE` | `5` | Connection pool size |
| `DB_MAX_OVERFLOW` | `10` | Max overflow connections |

---
